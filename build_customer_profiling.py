"""
Iterate the link got from the json file generated by scrape_amazon_review.py to get all posts by each customer
"""
import itertools
import json
from datetime import datetime
import emoji
from lexical_diversity import lex_div as ld
import textstat

import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import string

import ssl



import requests
import time
from bs4 import BeautifulSoup

from requests_html import HTMLSession

from scrape_amazon_review import Reviews

first_date_available_list = ["June 1, 2021", "January 12, 2016", "February 14, 2019", "May 30, 2021",
                             "September 13, 2019", "September 24, 2021", "August 17, 2020", "February 15, 2011",
                             "February 1, 2012", "April 10, 2020", "October 11, 2017"]
count_review = 0

try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

nltk.download('punkt')
nltk.download('stopwords')

stop_words = set(stopwords.words("english"))
punctuation = set(string.punctuation)
removing_words = stop_words | punctuation

review_length_list = []
count_keyword_list = []
word_diversity_measure_list = []
word_complexity_measure_list = []
whether_image_list = []
whether_emoji_list = []
timing_list = []
count_helpful_list = []



def read_json(json_address):
    with open(json_address, 'r') as f:
        # Load the contents of the file into a Python object
        data = json.load(f)
    flattened_list = list(itertools.chain(*data))
    return flattened_list


def get_count_review(review_list):
    global count_review
    count_review = len(review_list)


def get_body_length(review_list):
    # point 1
    for entry in review_list:
        review_length_list.append(len(entry["body"].split(" ")))


def get_keywords(review_list):
    # point 2
    keywords = []
    for entry in review_list:
        tokens = word_tokenize(entry["body"])
        keywords.append([token for token in tokens if not token.lower() in removing_words])
    return keywords


def get_keywords_number(keywords):
    # point 2
    for ks in keywords:
        count_keyword_list.append(len(ks))


def get_word_diversity(review_list):
    # point 3
    for entry in review_list:
        word_diversity_measure_list.append(ld.mtld(ld.flemmatize(entry["body"])))


def get_word_complexity(review_list):
    # point 4
    for entry in review_list:
        word_complexity_measure_list.append(textstat.automated_readability_index(entry["body"]))


def get_whether_image(review_list):
    # point 5
    for dictionary in review_list:
        whether_image_list.append(dictionary["image_usage"])


def get_whether_emoji(review_list):
    # point 6
    for dictionary in review_list:
        value = dictionary["body"]
        for character in value:
            if character in emoji.EMOJI_DATA:
                whether_emoji_list.append(1)
                break
        whether_emoji_list.append(0)


def get_timing(review_list):
    # point 8
    for dictionary in review_list:
        review_date = dictionary["written_date"]
        index = dictionary["product_index"]
        first_available_date = first_date_available_list[index]
        date_1 = datetime.strptime(review_date, '%B %d, %Y')
        date_2 = datetime.strptime(first_available_date, '%B %d, %Y')
        timing = date_1 - date_2
        timing_list.append(timing.days)


def get_count_helpful(review_list):
    # point 9
    for dictionary in review_list:
        count_helpful_list.append(dictionary["people_count"])


def buildup_dataset(review_list):
    get_count_review(review_list)

    get_body_length(review_list)
    keywords = get_keywords(review_list)
    get_keywords_number(keywords)
    get_word_diversity(review_list)
    get_word_complexity(review_list)
    get_whether_image(review_list)
    get_whether_emoji(review_list)
    get_timing(review_list)
    get_count_helpful(review_list)
    print(review_length_list)
    print(count_keyword_list)
    print(word_diversity_measure_list)
    print(word_complexity_measure_list)
    print(whether_image_list)
    print(whether_emoji_list)
    print(timing_list)
    print(count_helpful_list)


if __name__ == '__main__':
    json_address = "final_file.json"
    review_list = read_json(json_address)
    buildup_dataset(review_list)
